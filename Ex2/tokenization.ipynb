{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa360d2",
   "metadata": {},
   "source": [
    "# Experimenting with tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421ec225",
   "metadata": {},
   "source": [
    "## NLTK-tokenization compared to Brown corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a765d5",
   "metadata": {},
   "source": [
    "In this notebook we will experiment with various tokenizers and see how they solve the corner cases.\n",
    "\n",
    "We start with nltk tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2e1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94e3045",
   "metadata": {},
   "source": [
    "We begin with the example sentence from the lecture 2. Apply the word_tokenize from nltk, and observe how it tokenizes the string. Compare to the examples in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c60b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent0 = \"For example, this isn't a well-formed sentence.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77283959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f41ed0f",
   "metadata": {},
   "source": [
    "We will now compare to the tokenization used in the Brown corpus. The Brown corpus is distributed in a tokenize form. To compare, we have to \"detokenize\" sentences from Brown, i.e., guess what the sentences might have looked like originally. To be sure to get it right, we will do it manually.\n",
    "\n",
    "Use NLTK's `word_tokenize` on the following sentence and compare to sentence 1750 in Brown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80d67d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Maybe motel-keeping isn't the nation's biggest industry.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a7ddd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3c2d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "brown_sentences = [s for s in brown.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b5aed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# brown_sentences[1750]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a90978",
   "metadata": {},
   "source": [
    "Reflect on the effect of the two different schemes for downstream tasks, e.g., tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f2a59",
   "metadata": {},
   "source": [
    "## Spacy\n",
    "Spacy is a toolbox for NLP different from NLTK. There are several differences between the two.\n",
    "- NLTK is a toolbox primary for educational purposes. It lets you experiment with several alternatives e.g., for tagging. Spacy is one paricular tool for analyzing language. One goal is to be fast.\n",
    "- NLTK works in pipelines. There is one tool for tokenization, then there is another tool for tagging which you apply next, etc. Spacy uses a model which does all the processes simulatenously. Afterwards you may read out tokenized text with or with tags, and more information as we will see later in the semester.\n",
    "- To use Spacy, you need to download (or train) a (neural) model for the language in questions before it can be put to use. There are models for several languages including Norwegian.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a55623e",
   "metadata": {},
   "source": [
    "### Get started\n",
    "You have to install Spacy. Spacy is already installed if you have run the recommended Anaconda set-up with in4080_2022 on your PC. It is also installed in the environment on the IFI cluster. Then you need to install a model. We have chosen the model `en_core_web_md` which isn't the biggest and best, but it will do for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b18e830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-04 10:52:25.292789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-04 10:52:25.292830: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29ba9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ae5db6",
   "metadata": {},
   "source": [
    "#### Your PC\n",
    "Follow the instruction on  https://spacy.io/usage/models to install the model on your own machine. You may then load it by\n",
    "```\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "```\n",
    "If you wonder where your model is stored, try\n",
    "```\n",
    "nlp.path\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9cd389",
   "metadata": {},
   "source": [
    "#### IFI cluster\n",
    "Models need some disk space. We have therefore downloaded a model you can import.\n",
    "```\n",
    "path = '/projects/nlp/spacy/en_core_web_md-3.3.0'\n",
    "nlp = spacy.load(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86de09ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/projects/nlp/spacy/en_core_web_md-3.3.0'\n",
    "nlp = spacy.load(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6aa86a",
   "metadata": {},
   "source": [
    "### Comparing Brown, NLTK and Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844b400e",
   "metadata": {},
   "source": [
    "To use Spacy, we first let it process a text (sentence, document), then we can extract information from the processed document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5e9af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc0 = nlp(sent0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c73e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "For example, this isn't a well-formed sentence."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93cf91e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok00 = doc0[4]\n",
    "tok00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ba50013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'is'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok00.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b161b5f3",
   "metadata": {},
   "source": [
    "To see the tokenized sentence, we may use\n",
    "```\n",
    "for token in doc0:\n",
    "    print(token.text)\n",
    "```\n",
    "Tokenize sent0 and sent1 and compare to Brown and NLTK. Where do NLTK and Spacy agree and where do they disagree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f8484fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d29d2e",
   "metadata": {},
   "source": [
    "Do you see any consequences for down-stream tasks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a46134e",
   "metadata": {},
   "source": [
    "Consider now sent2. How is tokenized by NLTK and by Spacy? How does this compare to sentence 36 in the Brown corpus? In particular, consider the end of the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333611b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent2 = \"It listed his wife's age as 74 and place of birth as Opelika , Ala.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94635fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b7951c",
   "metadata": {},
   "source": [
    "We have seen that both NLTK and Spacy splits e.g., *what's*, but they handle hyphenated expressions differently. What happens when the two phenomens are intermingled. Consider sentence 55310 from the Brown corpus, here sent3. How is it tokenized by the three models? How would you tokenize it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd883aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"He didn't know what was so tough about Vivian's world, slopping around Nassau with what's-his-name.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent3 = (\"He didn't know what was so tough about Vivian's world, \" + \n",
    "\"slopping around Nassau with what's-his-name.\")\n",
    "sent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48148db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
